{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krisanthi/Customer-Churn-Prediction-Model/blob/main/CM2604_Churn_Prediction_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o2EZMkfxWIS"
      },
      "source": [
        "# CM2604 Machine Learning Coursework\n",
        "## Telco Customer Churn Prediction\n",
        "\n",
        "**Module:** CM2604 Machine Learning  \n",
        "**RGU Student ID:** 2425596  \n",
        "**IIT Student ID:** 20232384  \n",
        "**Student Name:** Krisanthi Segar  \n",
        "\n",
        "---\n",
        "\n",
        "### Project Overview\n",
        "This project aims to predict customer churn in a telecommunications company using machine learning techniques. I implement and compare a **Decision Tree Classifier** (with GridSearchCV hyperparameter tuning) and a **Neural Network** model.\n",
        "\n",
        "**Dataset:** Telco Customer Churn (Kaggle)  \n",
        "**Target Variable:** Churn (Yes/No - Binary Classification)  \n",
        "**Models:** Decision Tree Classifier, Neural Network (MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_lETPx9xWIU"
      },
      "source": [
        "---\n",
        "# 1. Setup and Data Loading\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7bpSSVwxWIV"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install --upgrade scikit-learn imbalanced-learn -q\n",
        "print(\"Packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrAtXSo5xWIW"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             roc_auc_score, roc_curve, classification_report,\n",
        "                             confusion_matrix, ConfusionMatrixDisplay)\n",
        "from scipy.stats import zscore\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k898RGy_xWIX"
      },
      "outputs": [],
      "source": [
        "# Upload the dataset\n",
        "print(\"Please upload the 'WA_Fn-UseC_-Telco-Customer-Churn.csv' file\")\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "print(f\"\\nFile '{filename}' uploaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRnyGK6WxWIX"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(filename)\n",
        "data = df.copy()\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DATASET LOADED SUCCESSFULLY\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nDataset shape: {data.shape}\")\n",
        "print(f\"Number of records: {data.shape[0]:,}\")\n",
        "print(f\"Number of features: {data.shape[1]}\")\n",
        "\n",
        "# Display first few rows\n",
        "print(\"\\n--- First 5 Rows ---\")\n",
        "display(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUceIZvfxWIX"
      },
      "source": [
        "---\n",
        "# TASK 1: Exploratory Data Analysis (EDA)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOTA9JgaxWIY"
      },
      "source": [
        "## 1.1 Dataset Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_nKsyurxWIY"
      },
      "outputs": [],
      "source": [
        "# Dataset Information\n",
        "print(\"=\" * 70)\n",
        "print(\"DATASET INFORMATION\")\n",
        "print(\"=\" * 70)\n",
        "data.info()\n",
        "\n",
        "print(\"\\n--- Column Names and Data Types ---\")\n",
        "for i, (col, dtype) in enumerate(zip(data.columns, data.dtypes), 1):\n",
        "    print(f\"{i:2}. {col:20} - {dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8AOpyQqxWIY"
      },
      "outputs": [],
      "source": [
        "# Missing Values Analysis\n",
        "print(\"=\" * 70)\n",
        "print(\"MISSING VALUES ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Standard null check\n",
        "print(\"\\n--- Standard Null Check ---\")\n",
        "null_counts = data.isnull().sum()\n",
        "print(null_counts[null_counts > 0] if null_counts.sum() > 0 else \"No standard null values found\")\n",
        "\n",
        "# TotalCharges special case - contains spaces as blanks\n",
        "print(f\"\\nTotalCharges data type (before conversion): {data['TotalCharges'].dtype}\")\n",
        "\n",
        "# Check for empty strings/spaces in TotalCharges\n",
        "empty_tc = data['TotalCharges'].replace(' ', '').eq('')\n",
        "print(f\"Empty strings/spaces in TotalCharges: {empty_tc.sum()}\")\n",
        "\n",
        "# Convert to numeric to reveal true missing values\n",
        "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\n",
        "missing_tc = data['TotalCharges'].isnull().sum()\n",
        "print(f\"\\nAfter converting to numeric:\")\n",
        "print(f\"Missing values in TotalCharges: {missing_tc}\")\n",
        "print(f\"Percentage of missing: {(missing_tc / len(data)) * 100:.2f}%\")\n",
        "\n",
        "# Show rows with missing TotalCharges\n",
        "if missing_tc > 0:\n",
        "    print(\"\\n--- Rows with Missing TotalCharges ---\")\n",
        "    display(data[data['TotalCharges'].isnull()][['customerID', 'tenure', 'MonthlyCharges', 'TotalCharges', 'Churn']])\n",
        "    print(\"\\nObservation: Missing TotalCharges are for customers with tenure=0 (new customers)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN_-d_KbxWIY"
      },
      "outputs": [],
      "source": [
        "# Duplicate Analysis\n",
        "print(\"=\" * 70)\n",
        "print(\"DUPLICATE ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Duplicate rows in dataset: {data.duplicated().sum()}\")\n",
        "print(f\"Duplicate customerIDs: {data['customerID'].duplicated().sum()}\")\n",
        "print(f\"Unique customers: {data['customerID'].nunique():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9zplMWaxWIY"
      },
      "source": [
        "## 1.2 Numerical Features Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAgFn239xWIY"
      },
      "outputs": [],
      "source": [
        "# Numerical Features Statistics\n",
        "print(\"=\" * 70)\n",
        "print(\"NUMERICAL FEATURES ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "print(\"\\n--- Statistical Summary ---\")\n",
        "display(data[numerical_cols].describe().round(2))\n",
        "\n",
        "print(\"\\n--- Key Observations ---\")\n",
        "print(f\"\\nTenure:\")\n",
        "print(f\"  Range: {data['tenure'].min()} to {data['tenure'].max()} months\")\n",
        "print(f\"  Mean: {data['tenure'].mean():.1f} months\")\n",
        "print(f\"  Median: {data['tenure'].median():.1f} months\")\n",
        "\n",
        "print(f\"\\nMonthlyCharges:\")\n",
        "print(f\"  Range: ${data['MonthlyCharges'].min():.2f} to ${data['MonthlyCharges'].max():.2f}\")\n",
        "print(f\"  Mean: ${data['MonthlyCharges'].mean():.2f}\")\n",
        "\n",
        "print(f\"\\nTotalCharges:\")\n",
        "print(f\"  Range: ${data['TotalCharges'].min():.2f} to ${data['TotalCharges'].max():.2f}\")\n",
        "print(f\"  Mean: ${data['TotalCharges'].mean():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE6uP4FgxWIY"
      },
      "source": [
        "## 1.3 Categorical Features Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MZK6crAxWIZ"
      },
      "outputs": [],
      "source": [
        "# Categorical Features Analysis\n",
        "print(\"=\" * 70)\n",
        "print(\"CATEGORICAL FEATURES ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "categorical_cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService',\n",
        "                    'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
        "                    'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
        "                    'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
        "\n",
        "print(f\"\\nNumber of Categorical Features: {len(categorical_cols)}\")\n",
        "\n",
        "# Check unique values per categorical column\n",
        "print(\"\\n--- Unique Values per Column ---\")\n",
        "for col in categorical_cols:\n",
        "    unique_vals = data[col].unique()\n",
        "    print(f\"{col}: {len(unique_vals)} unique values - {list(unique_vals)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElzGrb1jxWIZ"
      },
      "outputs": [],
      "source": [
        "# Value counts for key categorical features\n",
        "print(\"\\n--- Value Distributions (Key Features) ---\")\n",
        "key_features = ['Contract', 'InternetService', 'PaymentMethod', 'gender']\n",
        "\n",
        "for col in key_features:\n",
        "    print(f\"\\n{col}:\")\n",
        "    vc = data[col].value_counts()\n",
        "    for val, count in vc.items():\n",
        "        pct = (count / len(data)) * 100\n",
        "        print(f\"  {val}: {count:,} ({pct:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f3NXLm9xWIZ"
      },
      "source": [
        "## 1.4 Target Variable Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZHdXnQmxWIZ"
      },
      "outputs": [],
      "source": [
        "# Target Variable Analysis\n",
        "print(\"=\" * 70)\n",
        "print(\"TARGET VARIABLE ANALYSIS (Churn)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "target_counts = data['Churn'].value_counts()\n",
        "target_pct = data['Churn'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(f\"\\nChurn Distribution:\")\n",
        "print(f\"  No (Did not churn):  {target_counts['No']:,} ({target_pct['No']:.2f}%)\")\n",
        "print(f\"  Yes (Churned):       {target_counts['Yes']:,} ({target_pct['Yes']:.2f}%)\")\n",
        "\n",
        "imbalance_ratio = target_counts['No'] / target_counts['Yes']\n",
        "print(f\"\\nClass Imbalance Ratio: {imbalance_ratio:.2f}:1 (No:Yes)\")\n",
        "print(\"\\n** Dataset exhibits significant class imbalance - SMOTE will be applied **\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhsjxPYCxWIZ"
      },
      "source": [
        "---\n",
        "# Data Visualizations\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ3TioMSxWIZ"
      },
      "outputs": [],
      "source": [
        "# Figure 1: Target Variable Distribution (Combined Bar + Annotation)\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "colors = ['#27ae60', '#e74c3c']  # Green for No, Red for Yes\n",
        "bars = ax.bar(target_counts.index, target_counts.values, color=colors, edgecolor='black', linewidth=1.2)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, count, pct in zip(bars, target_counts.values, target_pct.values):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height + 100,\n",
        "            f'{count:,}\\n({pct:.1f}%)',\n",
        "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "ax.set_xlabel('Churn Status', fontsize=12)\n",
        "ax.set_ylabel('Number of Customers', fontsize=12)\n",
        "ax.set_title('Figure 1: Customer Churn Distribution', fontsize=14, fontweight='bold')\n",
        "ax.set_ylim(0, max(target_counts.values) * 1.15)\n",
        "\n",
        "# Add imbalance ratio annotation\n",
        "ax.annotate(f'Imbalance Ratio: {imbalance_ratio:.2f}:1',\n",
        "            xy=(0.95, 0.95), xycoords='axes fraction',\n",
        "            fontsize=11, ha='right', va='top',\n",
        "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig1_churn_distribution.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Figure 1 saved: fig1_churn_distribution.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_cBC3lYxWIZ"
      },
      "outputs": [],
      "source": [
        "# Figure 2: Correlation Heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "corr_matrix = data[numerical_cols].corr()\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Upper triangle mask\n",
        "\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='RdYlBu_r', center=0, fmt='.3f',\n",
        "            square=True, linewidths=0.5, annot_kws={'size': 14, 'weight': 'bold'},\n",
        "            cbar_kws={'shrink': 0.8})\n",
        "\n",
        "plt.title('Figure 2: Correlation Heatmap of Numerical Features', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig2_correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Figure 2 saved: fig2_correlation_heatmap.png\")\n",
        "print(f\"\\nKey Correlations:\")\n",
        "print(f\"  Tenure - TotalCharges: {corr_matrix.loc['tenure', 'TotalCharges']:.3f} (Strong positive)\")\n",
        "print(f\"  Tenure - MonthlyCharges: {corr_matrix.loc['tenure', 'MonthlyCharges']:.3f}\")\n",
        "print(f\"  MonthlyCharges - TotalCharges: {corr_matrix.loc['MonthlyCharges', 'TotalCharges']:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vgf39fwqxWIZ"
      },
      "outputs": [],
      "source": [
        "# Figure 3: Distribution of Numerical Features (Histograms with KDE)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
        "\n",
        "for i, (col, ax, color) in enumerate(zip(numerical_cols, axes, colors)):\n",
        "    # Histogram with KDE\n",
        "    data[col].dropna().hist(bins=30, ax=ax, color=color, edgecolor='black', alpha=0.7, density=True)\n",
        "    data[col].dropna().plot.kde(ax=ax, color='darkblue', linewidth=2)\n",
        "\n",
        "    # Add mean line\n",
        "    mean_val = data[col].mean()\n",
        "    ax.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.1f}')\n",
        "\n",
        "    ax.set_xlabel(col, fontsize=11)\n",
        "    ax.set_ylabel('Density', fontsize=11)\n",
        "    ax.set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
        "    ax.legend(loc='upper right')\n",
        "\n",
        "plt.suptitle('Figure 3: Distribution of Numerical Features', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig3_numerical_distributions.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Figure 3 saved: fig3_numerical_distributions.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoRWYWaZxWIZ"
      },
      "outputs": [],
      "source": [
        "# Figure 4: Box Plots for Outlier Detection\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
        "\n",
        "for i, (col, ax, color) in enumerate(zip(numerical_cols, axes, colors)):\n",
        "    bp = ax.boxplot(data[col].dropna(), patch_artist=True, notch=True)\n",
        "    bp['boxes'][0].set_facecolor(color)\n",
        "    bp['boxes'][0].set_alpha(0.7)\n",
        "    bp['medians'][0].set_color('red')\n",
        "    bp['medians'][0].set_linewidth(2)\n",
        "\n",
        "    # Calculate outliers\n",
        "    Q1 = data[col].quantile(0.25)\n",
        "    Q3 = data[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    outliers = data[(data[col] < Q1 - 1.5*IQR) | (data[col] > Q3 + 1.5*IQR)][col]\n",
        "\n",
        "    ax.set_ylabel(col, fontsize=11)\n",
        "    ax.set_title(f'{col}\\n(Outliers: {len(outliers)})', fontsize=12, fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Figure 4: Box Plots for Outlier Detection', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig4_boxplots.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Figure 4 saved: fig4_boxplots.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5UbcIRzxWIa"
      },
      "outputs": [],
      "source": [
        "# Figure 5: Churn Rate by Contract Type, Internet Service, and Payment Method\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
        "\n",
        "analysis_cols = ['Contract', 'InternetService', 'PaymentMethod']\n",
        "\n",
        "for ax, col in zip(axes, analysis_cols):\n",
        "    # Calculate churn rate per category\n",
        "    churn_rate = data.groupby(col)['Churn'].apply(lambda x: (x == 'Yes').mean() * 100)\n",
        "    churn_rate = churn_rate.sort_values(ascending=True)\n",
        "\n",
        "    colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(churn_rate)))\n",
        "    bars = ax.barh(churn_rate.index, churn_rate.values, color=colors, edgecolor='black')\n",
        "\n",
        "    # Add value labels\n",
        "    for bar, val in zip(bars, churn_rate.values):\n",
        "        ax.text(val + 1, bar.get_y() + bar.get_height()/2, f'{val:.1f}%',\n",
        "                va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "    ax.set_xlabel('Churn Rate (%)', fontsize=11)\n",
        "    ax.set_title(f'Churn Rate by {col}', fontsize=12, fontweight='bold')\n",
        "    ax.set_xlim(0, max(churn_rate.values) * 1.2)\n",
        "\n",
        "plt.suptitle('Figure 5: Churn Rate by Key Categorical Features', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig5_churn_by_categories.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Figure 5 saved: fig5_churn_by_categories.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrqzHORcxWIa"
      },
      "outputs": [],
      "source": [
        "# Figure 6: Numerical Features vs Churn (Violin Plots)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "for i, (col, ax) in enumerate(zip(numerical_cols, axes)):\n",
        "    sns.violinplot(x='Churn', y=col, data=data, ax=ax, palette=['#27ae60', '#e74c3c'])\n",
        "    ax.set_xlabel('Churn', fontsize=11)\n",
        "    ax.set_ylabel(col, fontsize=11)\n",
        "    ax.set_title(f'{col} by Churn Status', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Figure 6: Numerical Features Distribution by Churn Status', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig6_violin_plots.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Figure 6 saved: fig6_violin_plots.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRdyDq_dxWIa"
      },
      "source": [
        "---\n",
        "# TASK 2A: Corpus Preparation\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7bnEFuaxWIa"
      },
      "outputs": [],
      "source": [
        "# Reload fresh data for preprocessing\n",
        "data = df.copy()\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CORPUS PREPARATION PIPELINE\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nInitial dataset shape: {data.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdE8WvpMxWIa"
      },
      "outputs": [],
      "source": [
        "# Step 1: Convert TotalCharges to numeric\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"Step 1: Convert TotalCharges to Numeric\")\n",
        "print(\"-\" * 50)\n",
        "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\n",
        "print(f\"Missing values revealed: {data['TotalCharges'].isnull().sum()}\")\n",
        "\n",
        "# Step 2: Impute missing values with median\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"Step 2: Impute Missing Values (Median)\")\n",
        "print(\"-\" * 50)\n",
        "median_val = data['TotalCharges'].median()\n",
        "data['TotalCharges'].fillna(median_val, inplace=True)\n",
        "print(f\"Median used for imputation: ${median_val:.2f}\")\n",
        "print(f\"Missing values after imputation: {data['TotalCharges'].isnull().sum()}\")\n",
        "\n",
        "# Step 3: Remove customerID\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"Step 3: Remove customerID (Non-predictive)\")\n",
        "print(\"-\" * 50)\n",
        "data.drop(columns=['customerID'], inplace=True)\n",
        "print(f\"customerID removed. New shape: {data.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffQ6ADVAxWIa"
      },
      "outputs": [],
      "source": [
        "# Step 4: Binary Encoding\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"Step 4: Binary Encoding\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "binary_maps = {\n",
        "    'gender': {'Male': 1, 'Female': 0},\n",
        "    'Partner': {'Yes': 1, 'No': 0},\n",
        "    'Dependents': {'Yes': 1, 'No': 0},\n",
        "    'PhoneService': {'Yes': 1, 'No': 0},\n",
        "    'PaperlessBilling': {'Yes': 1, 'No': 0},\n",
        "    'Churn': {'Yes': 1, 'No': 0}\n",
        "}\n",
        "\n",
        "for col, mapping in binary_maps.items():\n",
        "    data[col] = data[col].map(mapping)\n",
        "    print(f\"  {col}: {mapping}\")\n",
        "\n",
        "# Step 5: One-Hot Encoding\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"Step 5: One-Hot Encoding\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "onehot_cols = ['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
        "               'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
        "               'Contract', 'PaymentMethod']\n",
        "\n",
        "print(f\"Columns before encoding: {len(data.columns)}\")\n",
        "data = pd.get_dummies(data, columns=onehot_cols, drop_first=True)\n",
        "print(f\"Columns after encoding: {len(data.columns)}\")\n",
        "print(f\"New columns created: {len(data.columns) - 10}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCGzomLQxWIa"
      },
      "outputs": [],
      "source": [
        "# Step 6: Outlier Removal\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"Step 6: Outlier Removal (Z-score > 3)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "print(f\"Rows before outlier removal: {len(data)}\")\n",
        "\n",
        "z_scores = np.abs(zscore(data[numerical_features]))\n",
        "outlier_mask = (z_scores < 3).all(axis=1)\n",
        "outliers_removed = len(data) - outlier_mask.sum()\n",
        "data = data[outlier_mask]\n",
        "\n",
        "print(f\"Rows after outlier removal: {len(data)}\")\n",
        "print(f\"Outliers removed: {outliers_removed} ({(outliers_removed/len(df))*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FQ7a2_8xWIa"
      },
      "outputs": [],
      "source": [
        "# Step 7: Feature Scaling\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"Step 7: Feature Scaling (StandardScaler)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "X = data.drop(columns=['Churn'])\n",
        "y = data['Churn']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
        "\n",
        "print(\"Numerical features scaled to mean=0, std=1\")\n",
        "print(f\"\\nScaled feature statistics:\")\n",
        "for col in numerical_features:\n",
        "    print(f\"  {col}: mean={X[col].mean():.4f}, std={X[col].std():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee5KHDpJxWIa"
      },
      "outputs": [],
      "source": [
        "# Step 8: SMOTE for Class Balancing\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"Step 8: SMOTE for Class Balancing\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "print(f\"Class distribution BEFORE SMOTE: {Counter(y)}\")\n",
        "\n",
        "smote = SMOTE(random_state=42, k_neighbors=5)\n",
        "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "\n",
        "print(f\"Class distribution AFTER SMOTE: {Counter(y_balanced)}\")\n",
        "print(f\"\\nSamples added: {len(y_balanced) - len(y)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw6qAT_bxWIa"
      },
      "outputs": [],
      "source": [
        "# Figure 7: Class Distribution Before and After SMOTE\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Before SMOTE\n",
        "before_counts = pd.Series(y).value_counts().sort_index()\n",
        "bars1 = axes[0].bar(['No Churn (0)', 'Churn (1)'], before_counts.values,\n",
        "                    color=['#27ae60', '#e74c3c'], edgecolor='black')\n",
        "axes[0].set_title('Before SMOTE', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Count', fontsize=11)\n",
        "for bar, val in zip(bars1, before_counts.values):\n",
        "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n",
        "                 f'{val:,}', ha='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "# After SMOTE\n",
        "after_counts = pd.Series(y_balanced).value_counts().sort_index()\n",
        "bars2 = axes[1].bar(['No Churn (0)', 'Churn (1)'], after_counts.values,\n",
        "                    color=['#27ae60', '#e74c3c'], edgecolor='black')\n",
        "axes[1].set_title('After SMOTE', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Count', fontsize=11)\n",
        "for bar, val in zip(bars2, after_counts.values):\n",
        "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n",
        "                 f'{val:,}', ha='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Figure 7: Class Distribution Before and After SMOTE', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig7_smote_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Figure 7 saved: fig7_smote_comparison.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAOpSGXLxWIa"
      },
      "outputs": [],
      "source": [
        "# Step 9: Train-Test Split\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"Step 9: Train-Test Split (80-20, Stratified)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_balanced, y_balanced,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=y_balanced\n",
        ")\n",
        "\n",
        "print(f\"Training set: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "print(f\"Testing set:  X_test={X_test.shape}, y_test={y_test.shape}\")\n",
        "print(f\"\\nTrain set class distribution: {Counter(y_train)}\")\n",
        "print(f\"Test set class distribution: {Counter(y_test)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CORPUS PREPARATION COMPLETE!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nFinal feature count: {X_train.shape[1]}\")\n",
        "print(f\"Total samples for training: {len(y_train):,}\")\n",
        "print(f\"Total samples for testing: {len(y_test):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0NEr2PhxWIb"
      },
      "source": [
        "---\n",
        "# TASK 2B: Model Implementation\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFBR4G7QxWIb"
      },
      "source": [
        "## Model 1: Decision Tree Classifier with GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLzLqiTkxWIb"
      },
      "outputs": [],
      "source": [
        "# Decision Tree with GridSearchCV\n",
        "print(\"=\" * 70)\n",
        "print(\"DECISION TREE CLASSIFIER WITH GRIDSEARCHCV\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [5, 10, 15, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "total_combinations = 2 * 5 * 3 * 3 * 3\n",
        "print(f\"\\nHyperparameter Grid:\")\n",
        "for param, values in param_grid.items():\n",
        "    print(f\"  {param}: {values}\")\n",
        "print(f\"\\nTotal parameter combinations: {total_combinations}\")\n",
        "print(f\"With 5-fold CV: {total_combinations * 5} fits\")\n",
        "\n",
        "print(\"\\nRunning GridSearchCV \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-HN07k7xWIb"
      },
      "outputs": [],
      "source": [
        "# Execute GridSearchCV\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(\n",
        "    dt, param_grid,\n",
        "    cv=5,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    return_train_score=True\n",
        ")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"Best Parameters Found:\")\n",
        "print(\"-\" * 50)\n",
        "for param, val in grid_search.best_params_.items():\n",
        "    print(f\"  {param}: {val}\")\n",
        "print(f\"\\nBest Cross-Validation F1-Score: {grid_search.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrmtGqLWxWIb"
      },
      "outputs": [],
      "source": [
        "# Decision Tree Evaluation with Overfitting Check\n",
        "best_dt = grid_search.best_estimator_\n",
        "\n",
        "# Predictions\n",
        "dt_train_pred = best_dt.predict(X_train)\n",
        "dt_test_pred = best_dt.predict(X_test)\n",
        "dt_train_proba = best_dt.predict_proba(X_train)[:, 1]\n",
        "dt_test_proba = best_dt.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate metrics for both train and test\n",
        "dt_train_accuracy = accuracy_score(y_train, dt_train_pred)\n",
        "dt_test_accuracy = accuracy_score(y_test, dt_test_pred)\n",
        "dt_train_f1 = f1_score(y_train, dt_train_pred)\n",
        "dt_test_f1 = f1_score(y_test, dt_test_pred)\n",
        "dt_train_auc = roc_auc_score(y_train, dt_train_proba)\n",
        "dt_test_auc = roc_auc_score(y_test, dt_test_proba)\n",
        "\n",
        "# Store test metrics\n",
        "dt_accuracy = dt_test_accuracy\n",
        "dt_precision = precision_score(y_test, dt_test_pred)\n",
        "dt_recall = recall_score(y_test, dt_test_pred)\n",
        "dt_f1 = dt_test_f1\n",
        "dt_roc_auc = dt_test_auc\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DECISION TREE EVALUATION RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\n--- Training vs Test Performance (Overfitting Check) ---\")\n",
        "print(f\"{'Metric':<15} {'Training':<12} {'Test':<12} {'Gap':<10}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'Accuracy':<15} {dt_train_accuracy:<12.4f} {dt_test_accuracy:<12.4f} {dt_train_accuracy - dt_test_accuracy:<10.4f}\")\n",
        "print(f\"{'F1-Score':<15} {dt_train_f1:<12.4f} {dt_test_f1:<12.4f} {dt_train_f1 - dt_test_f1:<10.4f}\")\n",
        "print(f\"{'ROC-AUC':<15} {dt_train_auc:<12.4f} {dt_test_auc:<12.4f} {dt_train_auc - dt_test_auc:<10.4f}\")\n",
        "\n",
        "# Overfitting warning\n",
        "if (dt_train_accuracy - dt_test_accuracy) > 0.1:\n",
        "    print(\"\\nWARNING: Potential overfitting detected (Accuracy gap > 10%)\")\n",
        "elif (dt_train_auc - dt_test_auc) > 0.1:\n",
        "    print(\"\\nWARNING: Potential overfitting detected (AUC gap > 10%)\")\n",
        "else:\n",
        "    print(\"\\nNo significant overfitting detected\")\n",
        "\n",
        "print(\"\\n--- Test Set Metrics ---\")\n",
        "print(f\"  Accuracy:  {dt_accuracy:.4f}\")\n",
        "print(f\"  Precision: {dt_precision:.4f}\")\n",
        "print(f\"  Recall:    {dt_recall:.4f}\")\n",
        "print(f\"  F1-Score:  {dt_f1:.4f}\")\n",
        "print(f\"  ROC-AUC:   {dt_roc_auc:.4f}\")\n",
        "\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "print(classification_report(y_test, dt_test_pred, target_names=['No Churn', 'Churn']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9U1ts2YxWIb"
      },
      "outputs": [],
      "source": [
        "# Figure 8: Decision Tree Confusion Matrix\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "cm_dt = confusion_matrix(y_test, dt_test_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=['No Churn', 'Churn'])\n",
        "disp.plot(cmap='Blues', ax=ax, values_format='d')\n",
        "\n",
        "plt.title('Figure 8: Decision Tree Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig8_dt_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "tn, fp, fn, tp = cm_dt.ravel()\n",
        "print(f\"Figure 8 saved: fig8_dt_confusion_matrix.png\")\n",
        "print(f\"\\nConfusion Matrix Breakdown:\")\n",
        "print(f\"  True Negatives (TN): {tn}\")\n",
        "print(f\"  False Positives (FP): {fp}\")\n",
        "print(f\"  False Negatives (FN): {fn}\")\n",
        "print(f\"  True Positives (TP): {tp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3nU1obAxWIb"
      },
      "outputs": [],
      "source": [
        "# Figure 9: Decision Tree Feature Importance\n",
        "feat_imp = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': best_dt.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"--- Top 10 Feature Importances ---\")\n",
        "display(feat_imp.head(10))\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "top15 = feat_imp.head(15)\n",
        "colors = plt.cm.viridis(np.linspace(0, 0.8, 15))\n",
        "bars = plt.barh(top15['Feature'], top15['Importance'], color=colors, edgecolor='black')\n",
        "\n",
        "plt.xlabel('Importance Score', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.title('Figure 9: Decision Tree - Top 15 Feature Importances', fontsize=14, fontweight='bold')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Add value labels\n",
        "for bar, val in zip(bars, top15['Importance']):\n",
        "    plt.text(val + 0.005, bar.get_y() + bar.get_height()/2,\n",
        "             f'{val:.3f}', va='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig9_dt_feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Figure 9 saved: fig9_dt_feature_importance.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZqGy5b-xWIb"
      },
      "source": [
        "## Model 2: Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9TvQSvWxWIb"
      },
      "outputs": [],
      "source": [
        "# Neural Network Model Architecture\n",
        "print(\"=\" * 70)\n",
        "print(\"NEURAL NETWORK MODEL\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nArchitecture Design:\")\n",
        "print(\"  Input Layer:  {} neurons\".format(X_train.shape[1]))\n",
        "print(\"  Hidden 1:     128 neurons (ReLU) + Dropout(0.3)\")\n",
        "print(\"  Hidden 2:     64 neurons (ReLU) + Dropout(0.3)\")\n",
        "print(\"  Hidden 3:     32 neurons (ReLU) + Dropout(0.2)\")\n",
        "print(\"  Hidden 4:     16 neurons (ReLU)\")\n",
        "print(\"  Output:       1 neuron (Sigmoid)\")\n",
        "print(\"\\nOptimizer: Adam (lr=0.001)\")\n",
        "print(\"Loss: Binary Crossentropy\")\n",
        "\n",
        "nn_model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "nn_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\n--- Model Summary ---\")\n",
        "nn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ0y3HPkxWIc"
      },
      "outputs": [],
      "source": [
        "# Train Neural Network with Early Stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nTraining Neural Network...\")\n",
        "print(\"(Early stopping enabled: patience=10)\\n\")\n",
        "\n",
        "history = nn_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgfHCZBhxWIc"
      },
      "outputs": [],
      "source": [
        "# Neural Network Evaluation with Overfitting Check\n",
        "# Predictions\n",
        "nn_train_proba = nn_model.predict(X_train, verbose=0).ravel()\n",
        "nn_test_proba = nn_model.predict(X_test, verbose=0).ravel()\n",
        "nn_train_pred = (nn_train_proba >= 0.5).astype(int)\n",
        "nn_test_pred = (nn_test_proba >= 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics for both train and test\n",
        "nn_train_accuracy = accuracy_score(y_train, nn_train_pred)\n",
        "nn_test_accuracy = accuracy_score(y_test, nn_test_pred)\n",
        "nn_train_f1 = f1_score(y_train, nn_train_pred)\n",
        "nn_test_f1 = f1_score(y_test, nn_test_pred)\n",
        "nn_train_auc = roc_auc_score(y_train, nn_train_proba)\n",
        "nn_test_auc = roc_auc_score(y_test, nn_test_proba)\n",
        "\n",
        "# Store test metrics\n",
        "nn_accuracy = nn_test_accuracy\n",
        "nn_precision = precision_score(y_test, nn_test_pred)\n",
        "nn_recall = recall_score(y_test, nn_test_pred)\n",
        "nn_f1 = nn_test_f1\n",
        "nn_roc_auc = nn_test_auc\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"NEURAL NETWORK EVALUATION RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\n--- Training vs Test Performance (Overfitting Check) ---\")\n",
        "print(f\"{'Metric':<15} {'Training':<12} {'Test':<12} {'Gap':<10}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'Accuracy':<15} {nn_train_accuracy:<12.4f} {nn_test_accuracy:<12.4f} {nn_train_accuracy - nn_test_accuracy:<10.4f}\")\n",
        "print(f\"{'F1-Score':<15} {nn_train_f1:<12.4f} {nn_test_f1:<12.4f} {nn_train_f1 - nn_test_f1:<10.4f}\")\n",
        "print(f\"{'ROC-AUC':<15} {nn_train_auc:<12.4f} {nn_test_auc:<12.4f} {nn_train_auc - nn_test_auc:<10.4f}\")\n",
        "\n",
        "# Overfitting warning\n",
        "if (nn_train_accuracy - nn_test_accuracy) > 0.1:\n",
        "    print(\"\\nWARNING: Potential overfitting detected (Accuracy gap > 10%)\")\n",
        "elif (nn_train_auc - nn_test_auc) > 0.1:\n",
        "    print(\"\\nWARNING: Potential overfitting detected (AUC gap > 10%)\")\n",
        "else:\n",
        "    print(\"\\nNo significant overfitting detected\")\n",
        "\n",
        "print(\"\\n--- Test Set Metrics ---\")\n",
        "print(f\"  Accuracy:  {nn_accuracy:.4f}\")\n",
        "print(f\"  Precision: {nn_precision:.4f}\")\n",
        "print(f\"  Recall:    {nn_recall:.4f}\")\n",
        "print(f\"  F1-Score:  {nn_f1:.4f}\")\n",
        "print(f\"  ROC-AUC:   {nn_roc_auc:.4f}\")\n",
        "\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "print(classification_report(y_test, nn_test_pred, target_names=['No Churn', 'Churn']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBZFzDd3xWIc"
      },
      "outputs": [],
      "source": [
        "# Figure 10: Neural Network Confusion Matrix\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "cm_nn = confusion_matrix(y_test, nn_test_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_nn, display_labels=['No Churn', 'Churn'])\n",
        "disp.plot(cmap='Oranges', ax=ax, values_format='d')\n",
        "\n",
        "plt.title('Figure 10: Neural Network Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig10_nn_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "tn, fp, fn, tp = cm_nn.ravel()\n",
        "print(f\"Figure 10 saved: fig10_nn_confusion_matrix.png\")\n",
        "print(f\"\\nConfusion Matrix Breakdown:\")\n",
        "print(f\"  True Negatives (TN): {tn}\")\n",
        "print(f\"  False Positives (FP): {fp}\")\n",
        "print(f\"  False Negatives (FN): {fn}\")\n",
        "print(f\"  True Positives (TP): {tp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJMpNsOfxWIc"
      },
      "outputs": [],
      "source": [
        "# Figure 11: Neural Network Training History\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss Plot\n",
        "axes[0].plot(history.history['loss'], label='Training Loss', color='blue', linewidth=2)\n",
        "axes[0].plot(history.history['val_loss'], label='Validation Loss', color='red', linewidth=2)\n",
        "axes[0].set_xlabel('Epoch', fontsize=11)\n",
        "axes[0].set_ylabel('Loss', fontsize=11)\n",
        "axes[0].set_title('Training and Validation Loss', fontsize=12, fontweight='bold')\n",
        "axes[0].legend(loc='upper right')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy Plot\n",
        "axes[1].plot(history.history['accuracy'], label='Training Accuracy', color='blue', linewidth=2)\n",
        "axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', color='red', linewidth=2)\n",
        "axes[1].set_xlabel('Epoch', fontsize=11)\n",
        "axes[1].set_ylabel('Accuracy', fontsize=11)\n",
        "axes[1].set_title('Training and Validation Accuracy', fontsize=12, fontweight='bold')\n",
        "axes[1].legend(loc='lower right')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Figure 11: Neural Network Training History', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig11_nn_training_history.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Figure 11 saved: fig11_nn_training_history.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwv6YgcpxWIc"
      },
      "source": [
        "---\n",
        "# Model Comparison\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvrcq8CRxWIc"
      },
      "outputs": [],
      "source": [
        "# Figure 12: ROC Curve Comparison\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Calculate ROC curves\n",
        "dt_fpr, dt_tpr, _ = roc_curve(y_test, dt_test_proba)\n",
        "nn_fpr, nn_tpr, _ = roc_curve(y_test, nn_test_proba)\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.plot(dt_fpr, dt_tpr, label=f'Decision Tree (AUC = {dt_roc_auc:.4f})',\n",
        "         color='blue', linewidth=2.5)\n",
        "plt.plot(nn_fpr, nn_tpr, label=f'Neural Network (AUC = {nn_roc_auc:.4f})',\n",
        "         color='orange', linewidth=2.5)\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier (AUC = 0.5)', linewidth=1.5, alpha=0.7)\n",
        "\n",
        "# Fill areas\n",
        "plt.fill_between(dt_fpr, dt_tpr, alpha=0.1, color='blue')\n",
        "plt.fill_between(nn_fpr, nn_tpr, alpha=0.1, color='orange')\n",
        "\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.title('Figure 12: ROC Curve Comparison', fontsize=14, fontweight='bold')\n",
        "plt.legend(loc='lower right', fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig12_roc_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Figure 12 saved: fig12_roc_comparison.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS7z1rBHxWIc"
      },
      "outputs": [],
      "source": [
        "# Model Comparison Summary\n",
        "print(\"=\" * 70)\n",
        "print(\"MODEL COMPARISON SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'],\n",
        "    'Decision Tree': [dt_accuracy, dt_precision, dt_recall, dt_f1, dt_roc_auc],\n",
        "    'Neural Network': [nn_accuracy, nn_precision, nn_recall, nn_f1, nn_roc_auc]\n",
        "})\n",
        "comparison_df['Difference'] = comparison_df['Neural Network'] - comparison_df['Decision Tree']\n",
        "comparison_df['Better Model'] = comparison_df.apply(\n",
        "    lambda row: 'Neural Network' if row['Difference'] > 0 else 'Decision Tree', axis=1\n",
        ")\n",
        "\n",
        "print(\"\\n\")\n",
        "display(comparison_df.round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTV2-M0CxWIc"
      },
      "outputs": [],
      "source": [
        "# Figure 13: Model Performance Comparison Bar Chart\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
        "dt_values = [dt_accuracy, dt_precision, dt_recall, dt_f1, dt_roc_auc]\n",
        "nn_values = [nn_accuracy, nn_precision, nn_recall, nn_f1, nn_roc_auc]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax.bar(x - width/2, dt_values, width, label='Decision Tree',\n",
        "               color='#3498db', edgecolor='black', linewidth=1.2)\n",
        "bars2 = ax.bar(x + width/2, nn_values, width, label='Neural Network',\n",
        "               color='#e74c3c', edgecolor='black', linewidth=1.2)\n",
        "\n",
        "# Add value labels on bars\n",
        "def add_labels(bars):\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height:.3f}',\n",
        "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                    xytext=(0, 3),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "add_labels(bars1)\n",
        "add_labels(bars2)\n",
        "\n",
        "ax.set_xlabel('Metric', fontsize=12)\n",
        "ax.set_ylabel('Score', fontsize=12)\n",
        "ax.set_title('Figure 13: Model Performance Comparison', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics, fontsize=11)\n",
        "ax.legend(loc='lower right', fontsize=11)\n",
        "ax.set_ylim(0, 1.1)\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig13_model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Figure 13 saved: fig13_model_comparison.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AstTMd1YxWIc"
      },
      "outputs": [],
      "source": [
        "# Final Comparison Analysis\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"FINAL ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Determine winner\n",
        "nn_wins = sum([1 for dt, nn in zip(dt_values, nn_values) if nn > dt])\n",
        "dt_wins = sum([1 for dt, nn in zip(dt_values, nn_values) if dt > nn])\n",
        "\n",
        "if nn_wins > dt_wins:\n",
        "    winner = \"Neural Network\"\n",
        "    f1_improvement = ((nn_f1 - dt_f1) / dt_f1) * 100\n",
        "else:\n",
        "    winner = \"Decision Tree\"\n",
        "    f1_improvement = ((dt_f1 - nn_f1) / nn_f1) * 100\n",
        "\n",
        "print(f\"\\nMetrics won by Neural Network: {nn_wins}/5\")\n",
        "print(f\"Metrics won by Decision Tree: {dt_wins}/5\")\n",
        "print(f\"\\nMost Suitable: {winner}\")\n",
        "print(f\"\\nF1-Score Improvement: {abs(f1_improvement):.1f}%\")\n",
        "print(f\"ROC-AUC Difference: {abs(nn_roc_auc - dt_roc_auc):.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 70)\n",
        "print(\"RECOMMENDATION:\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"The {winner} model is recommended for deployment based on overall\")\n",
        "print(\"performance across all evaluation metrics.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3OxmNkpxWId"
      },
      "source": [
        "---\n",
        "# TASK 3: AI Ethics - 10%\n",
        "---\n",
        "\n",
        "## Development Phase Strategies\n",
        "\n",
        "### 1. Data Privacy\n",
        "- **customerID Removal:** The unique customer identifier was removed to eliminate Personally Identifiable Information (PII) from the training data\n",
        "- **No Direct Identifiers:** The model does not use names, addresses, or contact information\n",
        "- **Anonymized Features:** All features are behavioral or service-related, not personally identifying\n",
        "\n",
        "### 2. Fairness Considerations\n",
        "- **Gender Feature Analysis:** The gender feature was included but monitored for potential bias\n",
        "- **Class Imbalance Handling:** SMOTE was applied to ensure the minority class (churners) is adequately represented\n",
        "- **Feature Importance Analysis:** Regular monitoring of feature importances to identify potential biased predictors\n",
        "\n",
        "### 3. Transparency\n",
        "- **Decision Tree Interpretability:** The Decision Tree model provides clear, interpretable decision rules\n",
        "- **Documentation:** All preprocessing steps and model decisions are documented\n",
        "- **Evaluation Metrics:** Multiple metrics (Accuracy, Precision, Recall, F1, AUC) provide comprehensive model assessment\n",
        "\n",
        "## Post-Deployment Strategies\n",
        "\n",
        "### 1. Performance Monitoring\n",
        "- **Monthly KPI Tracking:** Monitor accuracy, F1-score, and AUC on new data monthly\n",
        "- **Drift Detection:** Implement statistical tests to detect feature distribution changes\n",
        "- **Alert Systems:** Automated alerts when performance drops below thresholds\n",
        "\n",
        "### 2. Bias Detection\n",
        "- **Quarterly Fairness Audits:** Regular analysis of predictions across demographic groups\n",
        "- **Disparate Impact Analysis:** Monitor for unequal prediction rates across protected classes\n",
        "- **Feedback Loops:** Incorporate customer feedback on prediction fairness\n",
        "\n",
        "### 3. Model Retraining\n",
        "- **Quarterly Updates:** Retrain models with new customer data every quarter\n",
        "- **A/B Testing:** Compare new model versions against current production model\n",
        "- **Version Control:** Maintain full history of model versions and their performance\n",
        "\n",
        "### 4. Human Oversight\n",
        "- **Retention Team Review:** All high-risk churn predictions reviewed by retention specialists\n",
        "- **Override Capability:** Human agents can override model predictions when appropriate\n",
        "- **Escalation Protocols:** Clear procedures for handling edge cases and complaints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAx1Sm0HxWId"
      },
      "outputs": [],
      "source": [
        "# Download all figures\n",
        "print(\"=\" * 70)\n",
        "print(\"DOWNLOADING ALL FIGURES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "figures = [\n",
        "    'fig1_churn_distribution.png',\n",
        "    'fig2_correlation_heatmap.png',\n",
        "    'fig3_numerical_distributions.png',\n",
        "    'fig4_boxplots.png',\n",
        "    'fig5_churn_by_categories.png',\n",
        "    'fig6_violin_plots.png',\n",
        "    'fig7_smote_comparison.png',\n",
        "    'fig8_dt_confusion_matrix.png',\n",
        "    'fig9_dt_feature_importance.png',\n",
        "    'fig10_nn_confusion_matrix.png',\n",
        "    'fig11_nn_training_history.png',\n",
        "    'fig12_roc_comparison.png',\n",
        "    'fig13_model_comparison.png'\n",
        "]\n",
        "\n",
        "print(\"\\nDownloading figures...\")\n",
        "for fig in figures:\n",
        "    try:\n",
        "        files.download(fig)\n",
        "        print(f\"   {fig}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   {fig} - Error: {str(e)}\")"
      ]
    }
  ]
}